{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Xilinx Logo](images/xilinx_logo.png \"Xilinx Logo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to capture video from a V4L2 device and display the output on a monitor using a DRM/KMS display device. This notebook uses the GStreamer multimedia framework.\n",
    "\n",
    "Three types of V4L2 devices are supported in this notebook:\n",
    "* Virtual Video Test driver (vivid)\n",
    "* USB Video Class (UVC) driver (usbcam)\n",
    "* MIPI CSI-2 capture pipeline using the Leopard IMX274 FMC daughter card (mipi)\n",
    "\n",
    "See nb2 for details on the mentioned V4L2 devices.\n",
    "\n",
    "The display device uses the Xilinx DRM/KMS driver. A video mixer supports alpha blending of multiple layers (also called planes). The plane formats are fixed and configured as follows:\n",
    "* 4 RGB planes (IDs: 30-33)\n",
    "* 4 YUY2 planes (IDs: 34-37)\n",
    "* 1 ARGB plane (ID: 38) - this is the primary plane used for setting the CRTC resolution\n",
    "\n",
    "The video mixer is connected to an HDMI encoder which drives the display. Both video mixer and HDMI encoder are implemented inside the FPGA.\n",
    "\n",
    "The video pipeline is composed of the following GStreamer elements:\n",
    "* The ``xlnxvideosrc`` element is used to capture video from a V4L2 device\n",
    "* The ``perf`` element is used to measure and print the frame rate\n",
    "* The ``kmssink`` element is used to display video on a monitor using the DRM/KMS kernel subsystem\n",
    "\n",
    "In this notebook, you will:\n",
    "1. Create a GStreamer video pipeline that captures video from a V4L2 device and displays the video on a monitor using DRM/KMS.\n",
    "2. Create a GStreamer pipeline graph and view it inside this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Imports and Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all python modules required for this notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display, clear_output\n",
    "import pydot\n",
    "import sys\n",
    "import time\n",
    "import gi\n",
    "gi.require_version('Gst', '1.0')\n",
    "gi.require_version(\"GstApp\", \"1.0\")\n",
    "from gi.repository import GObject, GLib, Gst, GstApp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the Base TRD notebook 3 (nb3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = \"nb3\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a directory for saving the pipeline graph as dot file. Set the GStreamer debug dot directory environement variable to point to that directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dotdir = \"/home/root/gst-dot/\" + nb\n",
    "!mkdir -p $dotdir\n",
    "%env GST_DEBUG_DUMP_DOT_DIR = $dotdir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the GStreamer library. Optionally enable debug (default off) and set the debug level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gst.init(None)\n",
    "Gst.debug_set_active(False)\n",
    "Gst.debug_set_default_threshold(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Create and Configure the GStreamer Elements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the ``xlnxvideosrc`` element and set some properties:\n",
    "* Set the ``io_mode`` to ``mmap`` for mapping device memory into application address space.\n",
    "* Set the ``src_type`` property to the desired source device e.g. ``vivid``, ``usbcam``, or ``mipi`` (see list above)\n",
    "\n",
    "The below code sets the default source type to ``vivid``. Update the value below next to the comment to select USB webcam or MIPI as capture device.\n",
    "\n",
    "If MIPI is selected, change the I/O mode to DMABUF (https://www.kernel.org/doc/html/v4.16/driver-api/dma-buf.html) which allows sharing of video buffers in 0-copy fashion between the source and sink elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_types = [\"vivid\", \"usbcam\", \"mipi\"]\n",
    "src_type = src_types[0] # Change the source type to vivid, usbcam, or mipi via list index\n",
    "\n",
    "io_mode = \"mmap\"\n",
    "if src_type == \"mipi\":\n",
    "    io_mode = \"dmabuf\"\n",
    "\n",
    "src = Gst.ElementFactory.make(\"xlnxvideosrc\")\n",
    "src.set_property(\"io-mode\", io_mode)\n",
    "src.set_property(\"src-type\", src_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a caps filter element to set the desired resolution (width and height) and format. The caps filter is configured to parse the mentioned properties from a string.\n",
    "\n",
    "The default resolution is set to 1280x720 and the format to YUY2 as those are commonly supported by USB webcams.\n",
    "\n",
    "If ``mipi`` is selected as source type, the maximum supported resolution is 3840x2160 (4K) at 60 fps. Note that the connected monitor also needs to support this resolution, otherwise the pipeline will fail during caps negotiation (see modeprint output below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_dict = {\n",
    "    \"720p\" : (\"1280\", \"720\"),\n",
    "    \"1080p\" : (\"1920\", \"1080\"),\n",
    "    \"2160p\" : (\"3840\", \"2160\")\n",
    "}\n",
    "res = \"720p\" # Change the resolution string to 720p, 1080p, or 2160p (mipi only)\n",
    "width = res_dict[res][0]\n",
    "height = res_dict[res][1]\n",
    "print(\"Selected resolution: \" + width + \"x\" + height)\n",
    "\n",
    "fmt = \"YUY2\"\n",
    "\n",
    "caps = Gst.ElementFactory.make(\"capsfilter\")\n",
    "cap = Gst.Caps.from_string(\"video/x-raw, width=\" + str(width) + \", height=\" + str(height) + \", format=\" + fmt)\n",
    "caps.set_property(\"caps\", cap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the ``perf`` element which is used to measure and print the frame rate while the video pipeline is running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf = Gst.ElementFactory.make(\"perf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The display driver creates a DRM device node with the module name ``xlnx``.\n",
    "\n",
    "List information about the DRM device by passing the module name to the ``modeprint`` utility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!modeprint xlnx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the ``kmssink`` element and set some properties:\n",
    "* Set the ``driver-name`` property to the Xilinx DRM driver name ``xlnx``.\n",
    "* Set the ``plane-id`` property to the ID value of the target plane. The default value 34 is set to the first YUY2 plane.\n",
    "* Set the ``fullscreen-overlay`` property to ``False`` to keep the CRTC set to the native display resolution.\n",
    "* Set the ``render-rectangle`` property to a quadruple consisting of x-offset, y-offset, width, and height. The render-rectangle allows moving a plane position on the display."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver_name = \"xlnx\"\n",
    "plane_id = 34\n",
    "xoff = 0 # Change this value to move the plane position in the x-direction\n",
    "yoff = 0 # Change this value to move the plane position in the y-direction\n",
    "fullscreen_overlay = False\n",
    "render_rectangle = Gst.ValueArray((xoff, yoff, width, height))\n",
    "\n",
    "sink = Gst.ElementFactory.make(\"kmssink\")\n",
    "sink.set_property(\"driver-name\", driver_name)\n",
    "sink.set_property(\"plane-id\", plane_id)\n",
    "sink.set_property(\"fullscreen-overlay\", fullscreen_overlay)\n",
    "sink.set_property(\"render-rectangle\", render_rectangle)\n",
    "\n",
    "# Uncomment the below code to read back the newly set property values\n",
    "#print(\"sink properties: \")\n",
    "#print(\"driver-name: \" + str(sink.get_property(\"driver-name\")))\n",
    "#print(\"plane-id: \" + str(sink.get_property(\"plane-id\")))\n",
    "#print(\"fullscreen-overlay: \" + str(sink.get_property(\"fullscreen-overlay\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Create and Run the GStreamer Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the pipeline, add all elements, and link them together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Gst.Pipeline.new(nb)\n",
    "\n",
    "pipeline.add(src)\n",
    "pipeline.add(caps)\n",
    "pipeline.add(perf)\n",
    "pipeline.add(sink)\n",
    "\n",
    "src.link(caps)\n",
    "caps.link(perf)\n",
    "perf.link(sink);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ``bus_call`` function listens on the bus for ``EOS``, ``INFO`` and ``ERROR`` events. In case of ``EOS`` or ``ERROR``, stop the pipeline (set to ``NULL`` state) and quit the main loop. \n",
    "\n",
    "For ``INFO`` and ``ERROR`` events, parse and print the info/error message. The ``perf`` element generates ``INFO`` events with the measured frame rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bus_call(bus, message, loop):\n",
    "    t = message.type\n",
    "    if t == Gst.MessageType.EOS:\n",
    "        sys.stdout.write(\"End-of-stream\\n\")\n",
    "        pipeline.set_state(Gst.State.NULL)\n",
    "        loop.quit()\n",
    "    elif t == Gst.MessageType.INFO:\n",
    "        err, info = message.parse_info()\n",
    "        sys.stderr.write(\"Info: %s\\n\" % info)\n",
    "        clear_output(wait=True)\n",
    "    elif t == Gst.MessageType.ERROR:\n",
    "        err, debug = message.parse_error()\n",
    "        sys.stderr.write(\"Error: %s: %s\\n\" % (err, debug))\n",
    "        pipeline.set_state(Gst.State.NULL)\n",
    "        loop.quit()\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start the pipeline (set to ``PLAYING`` state), create the main loop and listen to messages on the bus. Register the ``bus_call`` callback function with the ``message`` signal of the bus. Start the main loop.\n",
    "\n",
    "The video will be displayed on the monitor. The frame rate will be printed and updated below the code cell.\n",
    "\n",
    "To stop the pipeline, click the square shaped icon labelled 'Interrupt the kernel' in the top menu bar. Create a dot graph of the pipeline topology before stopping the pipeline. Quit the main loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.set_state(Gst.State.PLAYING);\n",
    "\n",
    "loop = GLib.MainLoop()\n",
    "bus = pipeline.get_bus()\n",
    "bus.add_signal_watch()\n",
    "bus.connect(\"message\", bus_call, loop)\n",
    "\n",
    "try:\n",
    "    loop.run()\n",
    "except:\n",
    "    sys.stdout.write(\"Interrupt caught\\n\")\n",
    "    Gst.debug_bin_to_dot_file(pipeline, Gst.DebugGraphDetails.ALL, nb)\n",
    "    pipeline.set_state(Gst.State.NULL)\n",
    "    loop.quit()\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. View the GStreamer Pipeline Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Register dot plugins for png export to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!dot -c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the dot file to png and display the pipeline graph. The image will be displayed below the following code cell. Double click on the generate image file to zoom in.\n",
    "\n",
    "**Note:** This step may take a few seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dotfile = dotdir + \"/\" + nb + \".dot\"\n",
    "graph = pydot.graph_from_dot_file(dotfile, 'utf-8')\n",
    "display(Image(graph[0].create(None, 'png', 'utf-8')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook you learned how to:\n",
    "1. Create a GStreamer pipeline that demonstrates how to capture video from a V4L2 device and display it on a monitor\n",
    "2. Export the pipeline topology as a dot file image and display it in the notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>CopyrightÂ© 2019 Xilinx</center>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
