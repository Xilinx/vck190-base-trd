{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Xilinx Logo](images/xilinx_logo.png \"Xilinx Logo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to split four video pipelines from a single source. Each branch runs through a 2d filter. As there are only two 2d filter kernels available in HW, one PL and one AIE kernel, each of the kernels are time-multiplexed across two elements. The display device contains a video mixer which allows targeting different video planes for the four branches with programmable x/y-offsets as well as width and height. In addition, the memory bandwidth is measured and plotted in a parallel notebook.\n",
    "\n",
    "Four types of V4L2 devices are supported in this notebook:\n",
    "* Virtual Video Test driver (vivid)\n",
    "* USB Video Class (UVC) driver (usb)\n",
    "* MIPI CSI-2 capture pipeline using the Leopard IMX274 FMC daughter card (mipi)\n",
    "* MIPI CSI-2 capture pipeline using the Avnet Multi-Camera FMC Module (mipi_quad)\n",
    "\n",
    "The video pipeline is composed of the following GStreamer elements:\n",
    "* The ``mediasrcbin`` element is used to capture video from a V4L2 device\n",
    "* The ``tee`` element is used to fork the input stream into multiple output streams, in this case 4 ouput streams\n",
    "* The ``sdxfilter2d`` element is used to implement a 2D convolution filter. A total of 4 instances is used, 2 using the PL kernel and 2 using the AIE kernel. \n",
    "* The ``perf`` element is used to measure and print the frame rate in one of the forked paths.\n",
    "* The ``kmssink`` element is used to display video on a monitor using the DRM/KMS kernel subsystem. Four planes are used to display the four streams.\n",
    "\n",
    "The default input video resolution is set to 1280x720, hence the monitor needs to support a minimum resolution of 2560x1440 (or higher).\n",
    "\n",
    "The ``base-trd-apm`` notebook is executed in parallel to this notebook ro measure and plot the memory bandwidth of the live video pipeline.\n",
    "\n",
    "In this notebook, you will:\n",
    "1. Create a GStreamer video pipeline with four branches using the ``parse_launch()`` API\n",
    "2. Run the ``base-trd-apm`` notebook to measure and plot the memory bandwidth while the video pipeline is running.\n",
    "3. Create a GStreamer pipeline graph and view it inside this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Imports and Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all python modules required for this notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display, clear_output\n",
    "import pydot\n",
    "import sys\n",
    "import gi\n",
    "gi.require_version('Gst', '1.0')\n",
    "from gi.repository import GObject, GLib, Gst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the Base TRD notebook 7 (nb7)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = \"nb7\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a directory for saving the pipeline graph as dot file. Set the GStreamer debug dot directory environement variable to point to that directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dotdir = \"/home/root/gst-dot/\" + nb\n",
    "!mkdir -p $dotdir\n",
    "%env GST_DEBUG_DUMP_DOT_DIR = $dotdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env XILINX_XRT = /usr\n",
    "%env XCL_BINDIR = /media/card"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the GStreamer library. Enable debug by setting the debug string, default set to level 1 for all categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gst.init(None)\n",
    "Gst.debug_set_threshold_from_string('*:1', True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Run the APM Notebook to Plot the Memory Bandwidth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open the ``base-trd-apm.ipynb`` notebook from the *File Browser* in a new tab. Execute the notebook by selecting *Run -> Run All Cells* from the Jupyter Lab menu bar. In section 4 of the APM notebook, a horizontal bar graph is shown that plots the currently consumed memory bandwidth split out by different AXI ports. For more information, read the APM notebook tutorial.\n",
    "\n",
    "Once you see the graph, right-click the graph and select *Create New View for Output*. This will create a new window/tab with just the graph. Now re-arrange the window by dragging it to the the right side of the screen so it shows side-by-side with the notebook window (see screenshot below).\n",
    "\n",
    "![APM Plot](images/apm-plot-nb6.jpg \"APM Plot\")\n",
    "\n",
    "Switch tabs back to the nb6 notebook and follow the steps below. Once the video pipeline is running, you will notice the bar graph will be updated live with the measured memory bandwidth numbers in Gbps. The screenshot shows video capture from the MIPI pipeline.\n",
    "\n",
    "**Note:** You can skip this step if your APM output view was already created previsouly. It will update automatically after running the video pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Create String Representation of GStreamer Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first pipeline consist of the following elements:\n",
    "* ``mediasrcbin``\n",
    "* ``caps``\n",
    "* ``kmssink``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describe the ``mediasrcbin`` element and its properties as string representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources = {\n",
    "    \"vivid\" : \"/dev/media0\",\n",
    "    \"mipi\" : \"/dev/media1\",\n",
    "    \"mipi_quad\" : \"/dev/media1\",\n",
    "    \"usb\" : \"/dev/media2\"\n",
    "}\n",
    "source = \"vivid\" # Change source to vivid, usb, or mipi using the dictionary value\n",
    "media_device = sources[source] \n",
    "print(source)\n",
    "\n",
    "#io_mode = \"mmap\"\n",
    "#if source == \"mipi\" or source == \"mipi_quad\":\n",
    "#    io_mode = \"dmabuf\"\n",
    "\n",
    "# validates if the current hw platform supports capture input mipi (IMX274 FMC) or mipi_quad_gmsl (Multi-Camera FMC) \n",
    "platform = str(open(\"/etc/xocl.txt\", \"r\").read().strip())\n",
    "if source == \"mipi\" and platform != \"vck190_base_trd_platform1\" or \\\n",
    "   source == \"mipi_quad\" and platform != \"vck190_base_trd_platform2\" :\n",
    "        raise Exception('This platform does not support %s as input, verify boot image' %source)\n",
    "\n",
    "src = \"mediasrcbin media-device=\" + media_device\n",
    "#src = \"mediasrcbin media-device=\" + media_device + \" io-mode=\" + io_mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describe the ``caps`` filter element as string representation. Set the framerate if MIPI or MIPI quad is selected as source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 1280\n",
    "height = 720\n",
    "fmt = \"YUY2\"\n",
    "\n",
    "caps = \"video/x-raw, width=\" + str(width) + \", height=\" + str(height) + \", format=\" + fmt \n",
    "\n",
    "if source == \"mipi\":\n",
    "    fps = \"60/1\"\n",
    "    caps = caps + \", framerate=\" + fps\n",
    "elif source == \"mipi_quad\":\n",
    "    fps = \"30/1\"\n",
    "    caps = caps + \", framerate=\" + fps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describe the filter2d elements which can be time-multiplexed across multiple video pipelines. In this case, four instances of the filter2d element are used:\n",
    "1. Two PL filter2d elements with different filter presets using a single HW kernel. The first preset produces a blur effect (top left), the second an emboss effect (top right).\n",
    "2. Two AIE filter2d elements using a single HW kernel. Both instances are using the horizontal sobel preset (bottom left and right)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_pl1 = \"sdxfilter2d filter-kernel=filter2d_pl_accel filter-preset=blur\"\n",
    "filter_pl2 = \"sdxfilter2d filter-kernel=filter2d_pl_accel filter-preset=emboss\"\n",
    "filter_aie1 = \"sdxfilter2d filter-kernel=filter2d_aie_accel\"\n",
    "filter_aie2 = filter_aie1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describe the ``kmssink`` element and its properties as string representation. Four planes with different x/y-offsets are used to display the four video streams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plane 1\n",
    "plane_id_1 = 37\n",
    "xoff_1 = 0\n",
    "yoff_1 = 0\n",
    "render_rectangle_1 = \"<\" + str(xoff_1) + \",\" + str(yoff_1) + \",\" + str(width) + \",\" + str(height) + \">\"\n",
    "sink_1 = \"kmssink plane-id=\" + str(plane_id_1) + \" render-rectangle=\" + render_rectangle_1  + \" sync=false\"\n",
    "# plane 2\n",
    "plane_id_2 = 38\n",
    "xoff_2 = width\n",
    "yoff_2 = 0\n",
    "render_rectangle_2 = \"<\" + str(xoff_2) + \",\" + str(yoff_2) + \",\" + str(width) + \",\" + str(height) + \">\"\n",
    "sink_2 = \"kmssink plane-id=\" + str(plane_id_2) + \" render-rectangle=\" + render_rectangle_2 + \" sync=false\"\n",
    "# plane 3\n",
    "plane_id_3 = 39\n",
    "xoff_3 = 0\n",
    "yoff_3 = height\n",
    "render_rectangle_3 = \"<\" + str(xoff_3) + \",\" + str(yoff_3) + \",\" + str(width) + \",\" + str(height) + \">\"\n",
    "sink_3 = \"kmssink plane-id=\" + str(plane_id_3) + \" render-rectangle=\" + render_rectangle_3 + \" sync=false\"\n",
    "# plane 4\n",
    "plane_id_4 = 40\n",
    "xoff_4 = width\n",
    "yoff_4 = height\n",
    "render_rectangle_4 = \"<\" + str(xoff_4) + \",\" + str(yoff_4) + \",\" + str(width) + \",\" + str(height) + \">\"\n",
    "sink_4 = \"kmssink plane-id=\" + str(plane_id_4) + \" render-rectangle=\" + render_rectangle_4 + \" sync=false\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a string representation of the pipeline by concatenating the individual element strings.\n",
    "\n",
    "If MIPI quad is selected, ``mediasrcbin`` is instantiated with four source pads, one for each sensor. the source pads are referenced by the name of the ``mediasrcbin`` element (``src``) followed by a dot (``src.``). For any other source, a ``tee`` element is used to fork the source. Each branch is referenced by the name of the ``tee`` element (``src``) followed by a dot (``src.``). The ``queue`` element is used to create a new thread for each branch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if source == \"mipi_quad\":\n",
    "    src = src + \" name=src \"\n",
    "    t = \"src. ! \" + caps\n",
    "else:\n",
    "    src = src + \" ! \" + caps + \" ! tee name=src \"\n",
    "    t = \"src. \"\n",
    "\n",
    "pipe = src + \\\n",
    "    t + \" ! queue ! \" + filter_pl1  + \" ! queue ! perf ! \" + sink_1 + \" \" + \\\n",
    "    t + \" ! queue ! \" + filter_pl2  + \" ! queue ! \" + sink_2 + \" \" + \\\n",
    "    t + \" ! queue ! \" + filter_aie1 + \" ! queue ! \" + sink_3 + \" \" + \\\n",
    "    t + \" ! queue ! \" + filter_aie2 + \" ! queue ! \" + sink_4\n",
    "\n",
    "print (pipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Create and Run the GStreamer Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parse the string representations of the first and second pipeline as a single pipeline graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Gst.parse_launch(pipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ``bus_call`` function listens on the bus for ``EOS``, ``INFO`` and ``ERROR`` events. In case of ``EOS`` or ``ERROR``, stop the pipeline (set to ``NULL`` state) and quit the main loop. \n",
    "\n",
    "For ``INFO`` and ``ERROR`` events, parse and print the info/error message. The ``perf`` element generates ``INFO`` events with the measured frame rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bus_call(bus, message, loop):\n",
    "    t = message.type\n",
    "    if t == Gst.MessageType.EOS:\n",
    "        sys.stdout.write(\"End-of-stream\\n\")\n",
    "        pipeline.set_state(Gst.State.NULL)\n",
    "        loop.quit()\n",
    "    elif t == Gst.MessageType.INFO:\n",
    "        err, info = message.parse_info()\n",
    "        sys.stderr.write(\"Info: %s\\n\" % info)\n",
    "        clear_output(wait=True)\n",
    "    elif t == Gst.MessageType.ERROR:\n",
    "        err, debug = message.parse_error()\n",
    "        sys.stderr.write(\"Error: %s: %s\\n\" % (err, debug))\n",
    "        pipeline.set_state(Gst.State.NULL)\n",
    "        loop.quit()\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start the pipeline (set to ``PLAYING`` state), create the main loop and listen to messages on the bus. Register the ``bus_call`` callback function with the ``message`` signal of the bus. Start the main loop.\n",
    "\n",
    "The video will be displayed on the monitor. The frame rate will be printed and updated below the code cell.\n",
    "\n",
    "To stop the pipeline, click the square shaped icon labelled 'Interrupt the kernel' in the top menu bar. Create a dot graph of the pipeline topology before stopping the pipeline. Quit the main loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.set_state(Gst.State.PLAYING);\n",
    "\n",
    "loop = GLib.MainLoop()\n",
    "bus = pipeline.get_bus()\n",
    "bus.add_signal_watch()\n",
    "bus.connect(\"message\", bus_call, loop)\n",
    "\n",
    "try:\n",
    "    loop.run()\n",
    "except:\n",
    "    sys.stdout.write(\"Interrupt caught\\n\")\n",
    "    Gst.debug_bin_to_dot_file(pipeline, Gst.DebugGraphDetails.ALL, nb)\n",
    "    pipeline.set_state(Gst.State.NULL)\n",
    "    loop.quit()\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. View the Pipeline dot Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Register dot plugins for png export to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!dot -c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the dot file to png and display the pipeline graph. The image will be displayed below the following code cell. Double click on the generate image file to zoom in.\n",
    "\n",
    "**Note:** This step may take a few seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dotfile = dotdir + \"/\" + nb + \".dot\"\n",
    "graph = pydot.graph_from_dot_file(dotfile, 'utf-8')\n",
    "display(Image(graph[0].create(None, 'png', 'utf-8')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook you learned how to:\n",
    "1. Create a GStreamer pipeline with four branches from a string representation using the ``parse_launch()`` API\n",
    "2. Plot the live memory bandwidth by running the APM notebook in parallel\n",
    "3. Export the pipeline topology as a dot file image and display it in the notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>CopyrightÂ© 2019 Xilinx</center>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
