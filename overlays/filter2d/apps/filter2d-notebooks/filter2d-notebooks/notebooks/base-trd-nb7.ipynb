{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Xilinx Logo](images/xilinx_logo.png \"Xilinx Logo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to split four video pipelines from a single source. Each branch runs through a 2d filter. This notebook uses 2d filter kernels available in PL HW. The kernels is time-multiplexed across four elements. The display device contains a video mixer which allows targeting different video planes for the four branches with programmable x/y-offsets as well as width and height. In addition, the memory bandwidth is measured and plotted in a parallel notebook.\n",
    "\n",
    "Five types of V4L2 devices are supported in this notebook:\n",
    "* Virtual Video Test driver (vivid)\n",
    "* USB Video Class (UVC) driver (usb)\n",
    "* MIPI CSI-2 capture pipeline using the Leopard IMX274 FMC daughter card (mipi)\n",
    "* HDMI Rx HDR10 capture pipeline (hdmi)\n",
    "\n",
    "The video pipeline is composed of the following GStreamer elements:\n",
    "* The ``mediasrcbin`` element is used to capture video from a V4L2 device\n",
    "* The ``tee`` element is used to fork the input stream into multiple output streams, in this case 4 ouput streams\n",
    "* The ``vvas_xfilter`` vvas infrastructure plugin used to implement a 2D convolution filter. A total of 4 instances is used using the PL kernel. \n",
    "* The ``perf`` element is used to measure and print the frame rate in one of the forked paths.\n",
    "* The ``kmssink`` element is used to display video on a monitor using the DRM/KMS kernel subsystem. Four planes are used to display the four streams.\n",
    "\n",
    "The default input video resolution is set to 1280x720, hence the monitor needs to support a minimum resolution of 2560x1440 (or higher).\n",
    "\n",
    "In this notebook, you will:\n",
    "1. Create a GStreamer video pipeline with four branches using the ``parse_launch()`` API\n",
    "2. Create a GStreamer pipeline graph and view it inside this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Imports and Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all python modules required for this notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display, clear_output\n",
    "import glob\n",
    "import subprocess\n",
    "import pydot\n",
    "import sys\n",
    "import os\n",
    "import gi\n",
    "gi.require_version('Gst', '1.0')\n",
    "from gi.repository import GObject, GLib, Gst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the Base TRD notebook 7 (nb7)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = \"nb7\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a directory for saving the pipeline graph as dot file. Set the GStreamer debug dot directory environment variable to point to that directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dotdir = \"/home/root/gst-dot/\" + nb\n",
    "!mkdir -p $dotdir\n",
    "%env GST_DEBUG_DUMP_DOT_DIR = $dotdir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validate the correct Vitis Overlay is available in the platform for this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"0000:00:00.0\"\n",
    "def xbutil_program_xclbin():\n",
    "    xclbin = os.path.join(\"/boot\", \"binary_container_1.xclbin\")\n",
    "    if os.path.exists(xclbin):\n",
    "        subprocess.run(['xbutil', 'program', '-d', device, '-u', xclbin], check=True)\n",
    "\n",
    "def xbutil_query_cu(cu):\n",
    "    proc = subprocess.run(['xbutil', 'examine', '-d', device], capture_output=True, encoding='utf8')\n",
    "    for line in proc.stdout.splitlines():\n",
    "        if cu in line:\n",
    "            return\n",
    "    raise Exception(\"Unable to find compute unit \\'\" + cu + \"\\'. Make sure the correct Vitis overlay is used.\")\n",
    "\n",
    "xbutil_program_xclbin()\n",
    "xbutil_query_cu(\"filter2d_pl_accel_0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the GStreamer library. Enable debug by setting the debug string, set default to level 1 for all categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gst.init(None)\n",
    "Gst.debug_set_threshold_from_string('*:1', True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Create String Representation of GStreamer Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ``get_media_by_device`` function returns the matching media node for a given video capture source. The following sources are supported in this notebook:\n",
    "* ``vivid`` : virtual video device (default)\n",
    "* ``usb`` : requires USB webcam\n",
    "* ``mipi`` : platform1 only, requires FMC card\n",
    "* ``hdmi`` : platform3 only, requires HDMI input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device_by_name(src):\n",
    "    sources = {\n",
    "        'vivid' : 'vivid',\n",
    "        \"usb\" : 'uvcvideo',\n",
    "        'mipi' : 'vcap_csi',\n",
    "        'hdmi' : 'vcap_hdmi'\n",
    "    }\n",
    "    if src == \"usb\" :\n",
    "        devices = glob.glob('/dev/video*')\n",
    "        devices.reverse()\n",
    "        for dev in devices:\n",
    "            proc = subprocess.run(['v4l2-ctl', '-d', dev, '--all'], capture_output=True, encoding='utf8')\n",
    "            for line in proc.stdout.splitlines():\n",
    "                if sources[src] in line:\n",
    "                    return dev\n",
    "    else :\n",
    "        devices = glob.glob('/dev/media*')\n",
    "        for dev in devices:\n",
    "            proc = subprocess.run(['media-ctl', '-d', dev, '-p'], capture_output=True, encoding='utf8')\n",
    "            for line in proc.stdout.splitlines():\n",
    "                if sources[src] in line:\n",
    "                    return dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describe the ``mediasrcbin`` element and its properties as string representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = \"vivid\" # Change source to vivid, usb, mipi, or hdmi\n",
    "\n",
    "device = get_device_by_name(source) \n",
    "if device is None:\n",
    "    raise Exception('Unable to find video source ' + source + '. Make sure the device is plugged in, powered, and the correct platform is used.')\n",
    "\n",
    "io_mode = \"mmap\"\n",
    "if source == \"mipi\" or source== \"hdmi\":\n",
    "    io_mode = \"dmabuf\"\n",
    "\n",
    "if source == \"usb\" :\n",
    "    src = \"v4l2src device=\" + device + \" name=src\"\n",
    "else :\n",
    "    src = \"mediasrcbin media-device=\" + device + \" name=src\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describe the ``caps`` filter element as string representation. Set the framerate if MIPI is selected as source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 1280\n",
    "height = 720\n",
    "fmt = \"YUY2\"\n",
    "\n",
    "caps = \"video/x-raw, width=\" + str(width) + \", height=\" + str(height) + \", format=\" + fmt \n",
    "\n",
    "if source == \"mipi\" or source== \"hdmi\":\n",
    "    fps = \"60/1\"\n",
    "    caps = caps + \", framerate=\" + fps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describe the filter2d elements which can be time-multiplexed across multiple video pipelines. In this case, four instances of the filter2d element are used:\n",
    "1. Four PL filter2d elements with different filter presets using a single HW kernel. Presets are being dynamically configured. the first preset produces an edge effect (top left), the second is an emboss effect (top right), the third preset produces a sharpen effect (bottom left), the last preset is identity, which takes the default config values from json file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_pl1 = 'vvas_xfilter kernels-config=/usr/share/vvas/base-trd/kernel_xfilter2d_pl.json dynamic-config={\"filter_preset\":\"edge\"}'\n",
    "filter_pl2 = 'vvas_xfilter kernels-config=/usr/share/vvas/base-trd/kernel_xfilter2d_pl.json dynamic-config={\"filter_preset\":\"emboss\"}'\n",
    "filter_pl3 = 'vvas_xfilter kernels-config=/usr/share/vvas/base-trd/kernel_xfilter2d_pl.json dynamic-config={\"filter_preset\":\"sharpen\"}'\n",
    "filter_pl4 = 'vvas_xfilter kernels-config=/usr/share/vvas/base-trd/kernel_xfilter2d_pl.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describe the ``kmssink`` element and its properties as string representation. Four planes with different x/y-offsets are used to display the four video streams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plane 1\n",
    "plane_id_1 = 38\n",
    "xoff_1 = 0\n",
    "yoff_1 = 0\n",
    "render_rectangle_1 = \"<\" + str(xoff_1) + \",\" + str(yoff_1) + \",\" + str(width) + \",\" + str(height) + \">\"\n",
    "sink_1 = \"kmssink plane-id=\" + str(plane_id_1) + \" render-rectangle=\" + render_rectangle_1  + \" sync=false\"\n",
    "# plane 2\n",
    "plane_id_2 = 39\n",
    "xoff_2 = width\n",
    "yoff_2 = 0\n",
    "render_rectangle_2 = \"<\" + str(xoff_2) + \",\" + str(yoff_2) + \",\" + str(width) + \",\" + str(height) + \">\"\n",
    "sink_2 = \"kmssink plane-id=\" + str(plane_id_2) + \" render-rectangle=\" + render_rectangle_2 + \" sync=false\"\n",
    "# plane 3\n",
    "plane_id_3 = 40\n",
    "xoff_3 = 0\n",
    "yoff_3 = height\n",
    "render_rectangle_3 = \"<\" + str(xoff_3) + \",\" + str(yoff_3) + \",\" + str(width) + \",\" + str(height) + \">\"\n",
    "sink_3 = \"kmssink plane-id=\" + str(plane_id_3) + \" render-rectangle=\" + render_rectangle_3 + \" sync=false\"\n",
    "# plane 4\n",
    "plane_id_4 = 41\n",
    "xoff_4 = width\n",
    "yoff_4 = height\n",
    "render_rectangle_4 = \"<\" + str(xoff_4) + \",\" + str(yoff_4) + \",\" + str(width) + \",\" + str(height) + \">\"\n",
    "sink_4 = \"kmssink plane-id=\" + str(plane_id_4) + \" render-rectangle=\" + render_rectangle_4 + \" sync=false\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a string representation of the pipeline by concatenating the individual element strings.\n",
    "\n",
    "A ``tee`` element is used to fork the source. Each branch is referenced by the name of the ``tee`` element (``src``) followed by a dot (``src.``). The ``queue`` element is used to create a new thread for each branch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if source ==\"usb\":\n",
    "    src = src + \" io-mode=\" + io_mode + \" ! \" + caps + \" ! tee name=t\"\n",
    "    t = \" t. \"\n",
    "else:\n",
    "    src = src + \" v4l2src0::io-mode=\" + io_mode + \" ! \" + caps + \" ! tee name=t\"\n",
    "    t = \" t. \"\n",
    "\n",
    "pipe = src + \\\n",
    "    t + \" ! queue ! \" + filter_pl1  + \" ! queue ! perf ! \" + sink_1 + \" \" + \\\n",
    "    t + \" ! queue ! \" + filter_pl2  + \" ! queue ! \" + sink_2 + \" \" + \\\n",
    "    t + \" ! queue ! \" + filter_pl3 + \" ! queue ! \" + sink_3 + \" \" + \\\n",
    "    t + \" ! queue ! \" + filter_pl4 + \" ! queue ! \" + sink_4\n",
    "\n",
    "print (pipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Create and Run the GStreamer Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parse the string representations of the first and second pipeline as a single pipeline graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Gst.parse_launch(pipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ``bus_call`` function listens on the bus for ``EOS``, ``INFO`` and ``ERROR`` events. In case of ``EOS`` or ``ERROR``, stop the pipeline (set to ``NULL`` state) and quit the main loop. \n",
    "\n",
    "For ``INFO`` and ``ERROR`` events, parse and print the info/error message. The ``perf`` element generates ``INFO`` events with the measured frame rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bus_call(bus, message, loop):\n",
    "    t = message.type\n",
    "    if t == Gst.MessageType.EOS:\n",
    "        sys.stdout.write(\"End-of-stream\\n\")\n",
    "        pipeline.set_state(Gst.State.NULL)\n",
    "        loop.quit()\n",
    "    elif t == Gst.MessageType.INFO:\n",
    "        err, info = message.parse_info()\n",
    "        sys.stderr.write(\"Info: %s\\n\" % info)\n",
    "        clear_output(wait=True)\n",
    "    elif t == Gst.MessageType.ERROR:\n",
    "        err, debug = message.parse_error()\n",
    "        sys.stderr.write(\"Error: %s: %s\\n\" % (err, debug))\n",
    "        pipeline.set_state(Gst.State.NULL)\n",
    "        loop.quit()\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start the pipeline (set to ``PLAYING`` state), create the main loop and listen to messages on the bus. Register the ``bus_call`` callback function with the ``message`` signal of the bus. Start the main loop.\n",
    "\n",
    "The video will be displayed on the monitor. The frame rate will be printed and updated below the code cell.\n",
    "\n",
    "To stop the pipeline, click the square shaped icon labelled 'Interrupt the kernel' in the top menu bar. Create a dot graph of the pipeline topology before stopping the pipeline. Quit the main loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.set_state(Gst.State.PLAYING);\n",
    "\n",
    "loop = GLib.MainLoop()\n",
    "bus = pipeline.get_bus()\n",
    "bus.add_signal_watch()\n",
    "bus.connect(\"message\", bus_call, loop)\n",
    "\n",
    "try:\n",
    "    loop.run()\n",
    "except:\n",
    "    sys.stdout.write(\"Interrupt caught\\n\")\n",
    "    Gst.debug_bin_to_dot_file(pipeline, Gst.DebugGraphDetails.ALL, nb)\n",
    "    pipeline.set_state(Gst.State.NULL)\n",
    "    loop.quit()\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. View the Pipeline dot Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the dot file to png and display the pipeline graph. The image will be displayed below the following code cell. Double click on the generate image file to zoom in.\n",
    "\n",
    "**Note:** This step may take a few seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dotfile = dotdir + \"/\" + nb + \".dot\"\n",
    "graph = pydot.graph_from_dot_file(dotfile, 'utf-8')\n",
    "display(Image(graph[0].create(None, 'png', 'utf-8')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook you learned how to:\n",
    "1. Create a GStreamer pipeline with four branches from a string representation using the ``parse_launch()`` API\n",
    "2. Export the pipeline topology as a dot file image and display it in the notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>Copyright© 2019 Xilinx</center>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
