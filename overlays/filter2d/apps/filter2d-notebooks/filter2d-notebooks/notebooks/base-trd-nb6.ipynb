{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Xilinx Logo](images/xilinx_logo.png \"Xilinx Logo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook uses notebook 2 as starting point and adds a 2D convolution filter accelerator into the video pipeline. Three versions of the 2D filter accelerator are available:\n",
    "* Implemented in software running on the A72 cores (PS) using standard OpenCV functions\n",
    "* Implemented in the PL using the Vitis Vision libraries and high-level synthesis (HLS)\n",
    "* Implemented in the AI Engine (AIE) using one AIE core with HLS-based data mover in the PL\n",
    "\n",
    "The 2D filter has a fixed kernel size of 3x3. It operates on the luma channel of a YUY2 image; the chroma channel is looped back unmodified.For the AIE version of the 2D filter, the chroma loopback is performed inside the data mover and only the chroma channel is forwarded to the AIE core that performs the convolution.\n",
    "The PL 2D filter performs the chroma loopback inside the kernel itself. In addition, the PL version has run-time programmable kernel coefficients and presets as well as well image dimensions. For the AIE version, the kernel coefficients are hard-coded to \"horizontal sobel\" and the image dimensions are fixed at 1280x720. This limitation will be fixed in a future release.\n",
    "\n",
    "For more information on the 2D convolution filter operation, see here: https://en.wikipedia.org/wiki/Kernel_(image_processing).\n",
    "\n",
    "The various 2D filter accelerators are integrated into Gstreamer using the Vitis Video Analytics SDK (VVAS) which provides a set of plugins and an abstraction layer on top of the Xilinx run-time (XRT). For more information, see here: https://xilinx.github.io/VVAS/.\n",
    "\n",
    "The video pipeline is composed of the following GStreamer elements:\n",
    "* The ``mediasrcbin`` element is used to capture video from a V4L2 device\n",
    "* The ``vvas_xfilter`` element is used to wrap the 2D convolution filter accelerator library\n",
    "* The ``jpegenc`` element is used to compress the raw video format to JPEG.\n",
    "* The ``appsink`` element is used to make the JPEG frames available to the jupyter notebook where they are displayed.\n",
    "\n",
    "In this notebook, you will:\n",
    "1. Create a GStreamer video pipeline that captures video from a V4L2 device, performs the 2D convolution, and displays the processed video inside this notebook.\n",
    "2. Switch between the different 2D filter implementations: PS, PL, or AIE\n",
    "3. Modify the filter presets or coefficients for the PS/PL implementations\n",
    "4. Create a GStreamer pipeline graph and view it inside this notebook.\n",
    "\n",
    "**Note:** The same 2D filter element can be applied in similar fashion to other notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Imports and Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all python modules required for this notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display, clear_output\n",
    "import glob\n",
    "import subprocess\n",
    "import pydot\n",
    "import sys\n",
    "import os\n",
    "import gi\n",
    "gi.require_version('Gst', '1.0')\n",
    "gi.require_version(\"GstApp\", \"1.0\")\n",
    "from gi.repository import GObject, GLib, Gst, GstApp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the Base TRD notebook 6 (nb6)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = \"nb6\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a directory for saving the pipeline graph as dot file. Set the GStreamer debug dot directory environment variable to point to that directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dotdir = \"/home/root/gst-dot/\" + nb\n",
    "!mkdir -p $dotdir\n",
    "%env GST_DEBUG_DUMP_DOT_DIR = $dotdir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validate the correct Vitis Overlay is available in the platform for this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"0000:00:00.0\"\n",
    "def xbutil_program_xclbin():\n",
    "    xclbin = \"/boot/binary_container_1.xclbin\"\n",
    "    if os.path.exists(xclbin):\n",
    "        subprocess.run(['xbutil', 'program', '-d', device, '-u', xclbin], check=True)\n",
    "\n",
    "def xbutil_query_cu(cu):\n",
    "    proc = subprocess.run(['xbutil', 'examine', '-d', device], capture_output=True, encoding='utf8')\n",
    "    for line in proc.stdout.splitlines():\n",
    "        if cu in line:\n",
    "            return\n",
    "    raise Exception(\"Unable to find compute unit \\'\" + cu + \"\\'. Make sure the correct Vitis overlay is used.\")\n",
    "\n",
    "xbutil_program_xclbin()\n",
    "xbutil_query_cu(\"filter2d_pl_accel\")\n",
    "#xbutil_query_cu(\"filter2d_aie_accel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the GStreamer library. Enable debug by setting the debug string, set default to level 1 for all categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gst.init(None)\n",
    "Gst.debug_set_threshold_from_string('*:1', True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Create and Configure the GStreamer Elements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ``get_media_by_device`` function returns the matching media node for a given video capture source. The following sources are supported in this notebook:\n",
    "* ``vivid`` : virtual video device (default)\n",
    "* ``usb`` : requires USB webcam\n",
    "* ``mipi`` : platform1 only, requires FMC card\n",
    "* ``hdmi`` : platform3 only, requires HDMI input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device_by_name(src):\n",
    "    sources = {\n",
    "        'vivid' : 'vivid',\n",
    "        \"usb\" : 'uvcvideo',\n",
    "        'mipi' : 'vcap_csi',\n",
    "        'hdmi' : 'vcap_hdmi'\n",
    "    }\n",
    "    if src == \"usb\" :\n",
    "        devices = glob.glob('/dev/video*')\n",
    "        devices.reverse()\n",
    "        for dev in devices:\n",
    "            proc = subprocess.run(['v4l2-ctl', '-d', dev, '--all'], capture_output=True, encoding='utf8')\n",
    "            for line in proc.stdout.splitlines():\n",
    "                if sources[src] in line:\n",
    "                    return dev\n",
    "    else :\n",
    "        devices = glob.glob('/dev/media*')\n",
    "        for dev in devices:\n",
    "            proc = subprocess.run(['media-ctl', '-d', dev, '-p'], capture_output=True, encoding='utf8')\n",
    "            for line in proc.stdout.splitlines():\n",
    "                if sources[src] in line:\n",
    "                    return dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the ``source`` based on available media devices for this platform. The default source is set to ``vivid``. Update the value next to the comment to select USB webcam or MIPI single-sensor if connected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = \"vivid\" # Change source to vivid, usb, mipi, hdmi\n",
    "\n",
    "device = get_device_by_name(source) \n",
    "if device is None:\n",
    "    raise Exception('Unable to find video source ' + source + '. Make sure the device is plugged in, powered, and the correct platform is used.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The source pads of the ``mediasrcbin`` element are created dynamically when it detects the incoming stream. The ``pad-added`` signal is emitted and this ``pad_added`` callback function is executed. It links the source pads of the mediasrcbin elements to the sink pads of the ``caps`` elements.\n",
    "\n",
    "Set the ``io-mode`` on the pad which propagates to the ``v4l2src`` node. If MIPI is selected, set the I/O mode to DMABUF (https://www.kernel.org/doc/html/v4.16/driver-api/dma-buf.html) which allows sharing of video buffers in 0-copy fashion between the source and sink elements. Otherwise, set the I/O mode to mmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_added(element, pad):\n",
    "    sink_pad = caps.get_static_pad(\"sink\")\n",
    "    if not sink_pad.is_linked():\n",
    "        pad.link(sink_pad)\n",
    "        if source == \"mipi\" or source == \"hdmi\":\n",
    "            pad.set_property(\"io-mode\", \"dmabuf\")\n",
    "        else:\n",
    "            pad.set_property(\"io-mode\", \"mmap\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: with newer firmware versions of \"Logitech BRIO camera\" or \"usb\", Brio device now supports two colour formats YUYV and GRAY8. mediasrcbin views Brio as a device with two sources within a single bin element. Inorder stream correctly using mediasrcbin, both devices in the bin element needs to stream data simultaneously. For ease of demonstration we use v4l2src element in case of \"usb\".\n",
    "\n",
    "Create the ``mediasrcbin`` element which is a bin element that uses the standard ``v4l2src`` element inside. Set the following some properties:\n",
    "* Set the ``media-device`` property to the desired media device node\n",
    "* Register the above ``pad_added`` callback function with the ``pad-added`` signal of the ``mediasrcbin`` element.\n",
    "\n",
    "Similarly if USB is the source device, create `` v4l2src `` element and set properties: \n",
    "* set the ``device`` property to the desired video node "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if source == \"usb\":\n",
    "    src = Gst.ElementFactory.make(\"v4l2src\")\n",
    "    src.set_property(\"device\", device)\n",
    "    src.set_property(\"io-mode\",\"mmap\")\n",
    "else: \n",
    "    src = Gst.ElementFactory.make(\"mediasrcbin\")\n",
    "    src.set_property(\"media-device\", device)\n",
    "    src.connect(\"pad_added\", pad_added);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a caps filter element to set the desired resolution (width and height) and format. The caps filter is configured to parse the mentioned properties from a string.\n",
    "\n",
    "The default resolution is set to 1280x720 and the format to YUY2 as those are commonly supported by USB webcams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 1280\n",
    "height = 720\n",
    "fmt = \"YUY2\"\n",
    "\n",
    "cap_string = \"video/x-raw, width=\" + str(width) + \", height=\" + str(height) + \", format=\" + fmt\n",
    "if source == \"mipi\" or source == \"hdmi\":\n",
    "    fps = \"60/1\"\n",
    "    cap_string = cap_string + \", framerate=\" + fps\n",
    "\n",
    "caps = Gst.ElementFactory.make(\"capsfilter\")\n",
    "cap = Gst.Caps.from_string(cap_string)\n",
    "caps.set_property(\"caps\", cap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the ``vvas_xfilter`` element. The ``kernels-config`` property is set to a json file path which contains configuration paramaters of the 2D filter implementation to be loaded at initialization time. Each implementation (PL, AIE, SW) has a dedicated json file. The ``dynamic-config`` property accepts a json string that is passed to the kernel each time the start function is called. This allows kernel parameters to be updated dynamically while the pipeline is running.\n",
    "\n",
    "The json file captures the following filter2d specific configuration paramaters:\n",
    "* ``debug_level`` : level for debug messages of this kernel library\n",
    "* ``in_fourcc`` : input format in fourcc notation; this TRD support 'YUY2' only\n",
    "* ``out_fourcc`` : output format in fourcc notation; this TRD supports 'YUY2' only\n",
    "* ``filter_preset`` : filter preset name that translates to a set of coefficients\n",
    "* ``filter_coefficients`` : 3x3 matrix of kernel coefficients; valid only if ``filter_preset`` is set to 'custom'\n",
    "\n",
    "**Note:** The AIE filter2d currently only supports 1280x720. If any other resolution is used, an assertion error is thrown. Please use the ``filter2d_pl_accel`` kernel instead or change the resolution accordingly. This limitation will be fixed in a future release."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsondir = \"/usr/share/vvas/base-trd/\"\n",
    "\n",
    "filter_kernels = [\"PL\", \"AIE\", \"SW\"]\n",
    "filter_kernel = filter_kernels[0] # Change filter kernel to PL, AIE or SW via list index\n",
    "print(\"Selected filter2d kernel: \" + filter_kernel)\n",
    "\n",
    "if filter_kernel == \"PL\":\n",
    "    jfile = jsondir + \"kernel_xfilter2d_pl.json\"\n",
    "elif filter_kernel == \"AIE\":\n",
    "    assert width == 1280 and height == 720, \"The AIE filter2d kernel only supports 720p!\"\n",
    "    # TODO\n",
    "else: # filter_kernel == \"SW\"\n",
    "    jfile = jsondir + \"kernel_xfilter2d_sw.json\"\n",
    "\n",
    "filter2d = Gst.ElementFactory.make(\"vvas_xfilter\")\n",
    "filter2d.set_property(\"kernels-config\", jfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The PL filter2d has two ways of programming the filter coefficients:\n",
    "1. by setting the ``filter_preset`` which translates to a set of coefficients\n",
    "2. by setting the ``filter_coefficients`` directly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we look at how to set the ``filter_preset`` parameter. The below command returns a list of supported presets to choose from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plist = [\n",
    "    \"blur\",\n",
    "    \"edge\",\n",
    "    \"horizontal edge\",\n",
    "    \"vertical edge\",\n",
    "    \"emboss\",\n",
    "    \"horizontal gradient\",\n",
    "    \"vertical gradient\",\n",
    "    \"identity\",\n",
    "    \"sharpen\",\n",
    "    \"horizontal sobel\",\n",
    "    \"vertical sobel\",\n",
    "    \"custom\"\n",
    "]\n",
    "\n",
    "def print_presets():\n",
    "    print(\"Supported filter presets:\\n\")\n",
    "    print('\\n'.join(plist) + '\\n')\n",
    "    \n",
    "print_presets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the ``filter_preset`` parameter to one of the supported values listed above e.g. \"horizontal sobel\" by passing the json string via the ``dynamic-config`` element property. The kernel library reads the preset and programs the filter coefficients behind the scene.\n",
    "\n",
    "**Note:** The filter-preset for the AIE filter2d is hard-coded to \"horizontal sobel\". Changing the property value will not affect the output image. This limitation will be fixed in a future release."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_preset(val):\n",
    "    if val in plist:\n",
    "        jstring = '{ \"filter_preset\" : \"' +  val + '\" }'\n",
    "        #print(jstring)\n",
    "        filter2d.set_property(\"dynamic-config\", jstring)\n",
    "    else:\n",
    "        raise Exception(\"Unsupported filter preset \\'\" + val + \"\\'\")\n",
    "\n",
    "set_preset(\"horizontal sobel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second way is to explicitly program the coefficients via the ``filter_coefficients`` parameter. Uncomment the last line in the next cell to program the coefficients via the ``dynamic-config`` element property.\n",
    "\n",
    "The filter coefficients are a 3x3 matrix of ``short int`` values. The default values in the below code snippet correspond to the identity matrix which results is a simple passthrough. The identity coefficients are as follows:\n",
    "```\n",
    " 0  0  0\n",
    " 0  1  0\n",
    " 0  0  0\n",
    "```\n",
    "\n",
    "To match the coefficients for \"horizontal sobel\", use the following matrix:\n",
    "```\n",
    " 1  2  1\n",
    " 0  0  0\n",
    "-1 -2 -1\n",
    "```\n",
    "\n",
    "**Note:** The ``coefficients`` for the AIE filter2d are hard-coded to \"horizontal sobel\". Changing the coefficients values will not affect the output image. This limitation will be fixed in a future release."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_coeff(val):\n",
    "    jstring = '{ \"filter_coefficients\" : ' + val + ' }'\n",
    "    #print(jstring)\n",
    "    filter2d.set_property(\"dynamic-config\", jstring)\n",
    "\n",
    "#set_coeff(\"[[0, 0, 0], [0, 1, 0], [0, 0, 0]]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the ``jpegenc`` element to compress the YUY2 video frame to JPEG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jpegenc = Gst.ElementFactory.make(\"jpegenc\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a callback function ``new_sample`` that retrieves the JPEG data from a GStreamer buffer object and passes it to the ``display`` function of the ``IPython.display`` module which displays the video frame inside the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_sample(sink):   \n",
    "    sample = sink.pull_sample()\n",
    "    buffer = sample.get_buffer()\n",
    "    ret, info = buffer.map(Gst.MapFlags.READ)\n",
    "    \n",
    "    display(Image(data=info.data))\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "    buffer.unmap(info)\n",
    "    \n",
    "    return Gst.FlowReturn.OK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the ``appsink`` element and set some properties:\n",
    "* Set the ``drop`` property to ``True`` to drop old buffers when the buffer queue is full\n",
    "* Set the ``max-buffers`` property to 0 to queue an unlimited number of buffers\n",
    "* Set the ``emit-signals`` property to ``True`` to emit the ``new-sample`` signal\n",
    "\n",
    "Register the above ``new_sample`` callback function with the ``new-sample`` signal of the ``appsink`` element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sink = Gst.ElementFactory.make(\"appsink\")\n",
    "sink.set_property(\"drop\", True)\n",
    "sink.set_property(\"max_buffers\", 0)\n",
    "sink.set_property(\"emit-signals\", True)\n",
    "sink.connect(\"new-sample\", new_sample);\n",
    "\n",
    "# Uncomment the below code to read back the newly set property values\n",
    "#print(\"appsink properties: \")\n",
    "#print(\"drop: \" + str(sink.get_property(\"drop\")))\n",
    "#print(\"max_buffers: \" + str(sink.get_property(\"max_buffers\")))\n",
    "#print(\"emit-signals: \" + str(sink.get_property(\"emit-signals\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Create and Run the GStreamer Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the pipeline, add all elements, and link them together.\n",
    "\n",
    "**Note:** Newly added or modified lines for adding in the filter2d element are marked with code comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Gst.Pipeline.new(nb)\n",
    "\n",
    "pipeline.add(src)\n",
    "pipeline.add(caps)\n",
    "pipeline.add(filter2d) # Create the filter2d element\n",
    "pipeline.add(jpegenc)\n",
    "pipeline.add(sink)\n",
    "\n",
    "if source == \"usb\":\n",
    "    src.link(caps)\n",
    "    caps.link(filter2d)\n",
    "    filter2d.link(jpegenc)\n",
    "    jpegenc.link(sink);\n",
    "else :\n",
    "    caps.link(filter2d) # Link the fiter2d element's sink pad to the caps element \n",
    "    filter2d.link(jpegenc) # Link the filter2d element's source pad to the jpegenc element\n",
    "    jpegenc.link(sink);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ``bus_call`` function listens on the bus for ``EOS`` and ``ERROR`` events. If any of these events occur, stop the pipeline (set to ``NULL`` state) and quit the main loop.\n",
    "\n",
    "In case of an ``ERROR`` event, parse and print the error message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bus_call(bus, message, loop):\n",
    "    t = message.type\n",
    "    if t == Gst.MessageType.EOS:\n",
    "        sys.stdout.write(\"End-of-stream\\n\")\n",
    "        pipeline.set_state(Gst.State.NULL)\n",
    "        loop.quit()\n",
    "    elif t == Gst.MessageType.ERROR:\n",
    "        err, debug = message.parse_error()\n",
    "        sys.stderr.write(\"Error: %s: %s\\n\" % (err, debug))\n",
    "        pipeline.set_state(Gst.State.NULL)\n",
    "        loop.quit()\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start the pipeline (set to ``PLAYING`` state), create the main loop and listen to messages on the bus. Register the ``bus_call`` callback function with the ``message`` signal of the bus. Start the main loop.\n",
    "\n",
    "The video frames will be displayed below the following code cell. \n",
    "\n",
    "To stop the pipeline, click the square shaped icon labelled 'Interrupt the kernel' in the top menu bar. Create a dot graph of the pipeline topology before stopping the pipeline. Quit the main loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.set_state(Gst.State.PLAYING);\n",
    "\n",
    "loop = GLib.MainLoop()\n",
    "bus = pipeline.get_bus()\n",
    "bus.add_signal_watch()\n",
    "bus.connect(\"message\", bus_call, loop)\n",
    "\n",
    "try:\n",
    "    loop.run()\n",
    "except:\n",
    "    sys.stdout.write(\"Interrupt caught\\n\")\n",
    "    Gst.debug_bin_to_dot_file(pipeline, Gst.DebugGraphDetails.ALL, nb)\n",
    "    pipeline.set_state(Gst.State.NULL)\n",
    "    loop.quit()\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. View the GStreamer Pipeline Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the dot file to png and display the pipeline graph. The image will be displayed below the following code cell. Double click on the generate image file to zoom in.\n",
    "\n",
    "**Note:** This step may take a few seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dotfile = dotdir + \"/\" + nb + \".dot\"\n",
    "graph = pydot.graph_from_dot_file(dotfile, 'utf-8')\n",
    "display(Image(graph[0].create(None, 'png', 'utf-8')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook you learned how to:\n",
    "1. Create a GStreamer pipeline that demonstrates how to capture video from a V4L2 device, process the video using a 2D convolution filter, and play it back inside the jupyter notebook\n",
    "2. Configure the 2D filter for different implementation modes: PS, PL, or AIE\n",
    "3. Program the filter coefficients directly or via presets\n",
    "4. Export the pipeline topology as a dot file image and display it in the notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>Copyright© 2019 Xilinx</center>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
